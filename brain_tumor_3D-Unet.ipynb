{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c1f6f18f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "from glob import glob\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from monai.transforms import (\n",
    "    LoadImaged, EnsureChannelFirstd, ScaleIntensityd, ResizeWithPadOrCropd,\n",
    "    ToTensord, Compose\n",
    ")\n",
    "from monai.networks import nets  # This replaces 'UnetEncoder'\n",
    "from monai.networks.layers import Norm\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tqdm import tqdm\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(\"Using device:\", device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f8d90cca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of samples: 739\n"
     ]
    }
   ],
   "source": [
    "class TumorDataset(Dataset):\n",
    "    def __init__(self, image_paths, labels, transforms=None):\n",
    "        self.image_paths = image_paths\n",
    "        self.labels = labels\n",
    "        self.transforms = transforms\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.image_paths)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        image_path = self.image_paths[idx]\n",
    "        label = self.labels[idx]\n",
    "        \n",
    "        # Load the image\n",
    "        image = nib.load(image_path).get_fdata()\n",
    "\n",
    "        sample = {'image': image, 'label': label}\n",
    "\n",
    "        if self.transforms:\n",
    "            sample = self.transforms(sample)\n",
    "\n",
    "        return sample\n",
    "\n",
    "# Set up transforms\n",
    "transforms = Compose([\n",
    "    LoadImaged(keys=[\"image\", \"label\"]),\n",
    "    EnsureChannelFirstd(keys=[\"image\", \"label\"]),\n",
    "    ScaleIntensityd(keys=[\"image\"]),\n",
    "    ResizeWithPadOrCropd(keys=[\"image\", \"label\"], spatial_size=(128, 128, 128)),\n",
    "    ToTensord(keys=[\"image\", \"label\"]),\n",
    "])\n",
    "\n",
    "# Prepare dataset\n",
    "image_paths = glob('D:/Major_Project_(CSE)/Brain_Tumor_Detection/combined_dataset/images/*.nii.gz')\n",
    "labels = pd.read_csv('D:/Major_Project_(CSE)/Brain_Tumor_Detection/combined_dataset/labels.csv')['label'].values\n",
    "\n",
    "# Create Dataset and DataLoader\n",
    "dataset = TumorDataset(image_paths=image_paths, labels=labels, transforms=transforms)\n",
    "train_loader = DataLoader(dataset, batch_size=2, shuffle=True, num_workers=4)\n",
    "\n",
    "print(f\"Number of samples: {len(dataset)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "13dbbcc9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "UNet(\n",
      "  (model): Sequential(\n",
      "    (0): Convolution(\n",
      "      (conv): Conv3d(1, 16, kernel_size=(3, 3, 3), stride=(2, 2, 2), padding=(1, 1, 1))\n",
      "      (adn): ADN(\n",
      "        (N): BatchNorm3d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (D): Dropout(p=0.0, inplace=False)\n",
      "        (A): ReLU()\n",
      "      )\n",
      "    )\n",
      "    (1): SkipConnection(\n",
      "      (submodule): Sequential(\n",
      "        (0): Convolution(\n",
      "          (conv): Conv3d(16, 32, kernel_size=(3, 3, 3), stride=(2, 2, 2), padding=(1, 1, 1))\n",
      "          (adn): ADN(\n",
      "            (N): BatchNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (D): Dropout(p=0.0, inplace=False)\n",
      "            (A): ReLU()\n",
      "          )\n",
      "        )\n",
      "        (1): SkipConnection(\n",
      "          (submodule): Sequential(\n",
      "            (0): Convolution(\n",
      "              (conv): Conv3d(32, 64, kernel_size=(3, 3, 3), stride=(2, 2, 2), padding=(1, 1, 1))\n",
      "              (adn): ADN(\n",
      "                (N): BatchNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "                (D): Dropout(p=0.0, inplace=False)\n",
      "                (A): ReLU()\n",
      "              )\n",
      "            )\n",
      "            (1): SkipConnection(\n",
      "              (submodule): Sequential(\n",
      "                (0): Convolution(\n",
      "                  (conv): Conv3d(64, 128, kernel_size=(3, 3, 3), stride=(2, 2, 2), padding=(1, 1, 1))\n",
      "                  (adn): ADN(\n",
      "                    (N): BatchNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "                    (D): Dropout(p=0.0, inplace=False)\n",
      "                    (A): ReLU()\n",
      "                  )\n",
      "                )\n",
      "                (1): SkipConnection(\n",
      "                  (submodule): Convolution(\n",
      "                    (conv): Conv3d(128, 256, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
      "                    (adn): ADN(\n",
      "                      (N): BatchNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "                      (D): Dropout(p=0.0, inplace=False)\n",
      "                      (A): ReLU()\n",
      "                    )\n",
      "                  )\n",
      "                )\n",
      "                (2): Convolution(\n",
      "                  (conv): ConvTranspose3d(384, 64, kernel_size=(3, 3, 3), stride=(2, 2, 2), padding=(1, 1, 1), output_padding=(1, 1, 1))\n",
      "                  (adn): ADN(\n",
      "                    (N): BatchNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "                    (D): Dropout(p=0.0, inplace=False)\n",
      "                    (A): ReLU()\n",
      "                  )\n",
      "                )\n",
      "              )\n",
      "            )\n",
      "            (2): Convolution(\n",
      "              (conv): ConvTranspose3d(128, 32, kernel_size=(3, 3, 3), stride=(2, 2, 2), padding=(1, 1, 1), output_padding=(1, 1, 1))\n",
      "              (adn): ADN(\n",
      "                (N): BatchNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "                (D): Dropout(p=0.0, inplace=False)\n",
      "                (A): ReLU()\n",
      "              )\n",
      "            )\n",
      "          )\n",
      "        )\n",
      "        (2): Convolution(\n",
      "          (conv): ConvTranspose3d(64, 16, kernel_size=(3, 3, 3), stride=(2, 2, 2), padding=(1, 1, 1), output_padding=(1, 1, 1))\n",
      "          (adn): ADN(\n",
      "            (N): BatchNorm3d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (D): Dropout(p=0.0, inplace=False)\n",
      "            (A): ReLU()\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (2): Convolution(\n",
      "      (conv): ConvTranspose3d(32, 1, kernel_size=(3, 3, 3), stride=(2, 2, 2), padding=(1, 1, 1), output_padding=(1, 1, 1))\n",
      "    )\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "from monai.networks.nets import UNet\n",
    "from monai.networks.layers import Norm\n",
    "\n",
    "# Define the 3D U-Net model\n",
    "model = UNet(\n",
    "    spatial_dims=3,\n",
    "    in_channels=1,  # Single-channel (grayscale) MRI images\n",
    "    out_channels=1,  # Tumor segmentation (binary: tumor vs no-tumor)\n",
    "    channels=(16, 32, 64, 128, 256),  # Channels at each level of the U-Net\n",
    "    kernel_size=3,\n",
    "    strides=(2, 2, 2, 2),  # Strides at each level (matching the number of channels)\n",
    "    norm=Norm.BATCH,\n",
    "    act=\"relu\",\n",
    ")\n",
    "\n",
    "# Move the model to the GPU\n",
    "model = model.to(device)\n",
    "\n",
    "# Print model summary\n",
    "print(model)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "22250a99",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🔧 Starting training...\n",
      "✅ Epoch 1 loss: 0.6902\n",
      "✅ Epoch 2 loss: 0.6419\n",
      "✅ Epoch 3 loss: 0.5675\n",
      "✅ Epoch 4 loss: 0.5577\n",
      "✅ Epoch 5 loss: 0.4825\n",
      "✅ Epoch 6 loss: 0.4466\n",
      "✅ Epoch 7 loss: 0.4195\n",
      "✅ Epoch 8 loss: 0.3975\n",
      "✅ Epoch 9 loss: 0.3793\n",
      "✅ Epoch 10 loss: 0.4244\n",
      "✅ Epoch 11 loss: 0.3773\n",
      "✅ Epoch 12 loss: 0.3424\n",
      "✅ Epoch 13 loss: 0.3366\n",
      "✅ Epoch 14 loss: 0.3182\n",
      "✅ Epoch 15 loss: 0.3057\n",
      "✅ Epoch 16 loss: 0.2951\n",
      "✅ Epoch 17 loss: 0.2848\n",
      "✅ Epoch 18 loss: 0.2748\n",
      "✅ Epoch 19 loss: 0.2651\n",
      "✅ Epoch 20 loss: 0.2560\n",
      "✅ Saved trained segmentation model!\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from monai.transforms import (\n",
    "    Compose, LoadImaged, EnsureChannelFirstd, ScaleIntensityd,\n",
    "    Resized, ToTensord\n",
    ")\n",
    "from monai.data import CacheDataset\n",
    "from monai.networks.nets import UNet\n",
    "\n",
    "# ------------------ Paths ------------------\n",
    "images_dir = \"D:/Major_Project_(CSE)/Brain_Tumor_Detection/combined_dataset/images\"\n",
    "labels_csv = \"D:/Major_Project_(CSE)/Brain_Tumor_Detection/combined_dataset/labels.csv\"\n",
    "\n",
    "# ------------------ Load labels ------------------\n",
    "df = pd.read_csv(labels_csv)\n",
    "if \"filename\" not in df.columns or \"label\" not in df.columns:\n",
    "    raise ValueError(\"❌ CSV must contain 'filename' and 'label' columns!\")\n",
    "\n",
    "# 🧠 Instead of scalar labels, we'll turn them into full-volume masks\n",
    "def generate_fake_mask(label):\n",
    "    # Returns a 5D tensor: (1, 1, 128, 128, 128) instead of (1, 128, 128, 128)\n",
    "    return torch.ones((1, 1, 128, 128, 128)) if label == 1 else torch.zeros((1, 1, 128, 128, 128))\n",
    "\n",
    "# Build dataset dicts\n",
    "data_dicts = [\n",
    "    {\"image\": os.path.join(images_dir, row[\"filename\"]), \"label\": int(row[\"label\"])}\n",
    "    for _, row in df.iterrows()\n",
    "]\n",
    "\n",
    "train_files, val_files = train_test_split(data_dicts, test_size=0.2, random_state=42)\n",
    "\n",
    "# ------------------ Transforms ------------------\n",
    "common_transforms = Compose([\n",
    "    LoadImaged(keys=[\"image\"]),\n",
    "    EnsureChannelFirstd(keys=[\"image\"]),\n",
    "    ScaleIntensityd(keys=[\"image\"]),\n",
    "    Resized(keys=[\"image\"], spatial_size=(128, 128, 128)),\n",
    "    ToTensord(keys=[\"image\"]),\n",
    "])\n",
    "\n",
    "# Apply transform to label manually\n",
    "class SegmentationDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, data, transforms):\n",
    "        self.data = data\n",
    "        self.transforms = transforms\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        d = self.transforms({\"image\": self.data[idx][\"image\"]})\n",
    "        label_tensor = generate_fake_mask(self.data[idx][\"label\"])  # shape: (1, 1, 128, 128, 128)\n",
    "        return {\"image\": d[\"image\"], \"label\": label_tensor}\n",
    "\n",
    "# ------------------ Dataset ------------------\n",
    "train_ds = SegmentationDataset(train_files, common_transforms)\n",
    "val_ds = SegmentationDataset(val_files, common_transforms)\n",
    "train_loader = DataLoader(train_ds, batch_size=1, shuffle=True)\n",
    "val_loader = DataLoader(val_ds, batch_size=1)\n",
    "\n",
    "# ------------------ Model ------------------\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = UNet(\n",
    "    spatial_dims=3,\n",
    "    in_channels=1,\n",
    "    out_channels=1,  # Binary segmentation\n",
    "    channels=(16, 32, 64, 128, 256),\n",
    "    strides=(2, 2, 2, 2),\n",
    "    num_res_units=2,\n",
    ").to(device)\n",
    "\n",
    "# ------------------ Training ------------------\n",
    "loss_function = nn.BCEWithLogitsLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=1e-4)\n",
    "\n",
    "num_epochs = 20\n",
    "print(\"🔧 Starting training...\")\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    epoch_loss = 0\n",
    "    for batch in train_loader:\n",
    "        inputs = batch[\"image\"].to(device)\n",
    "        labels = batch[\"label\"].to(device)\n",
    "\n",
    "        # Squeeze the labels to match the shape of outputs\n",
    "        labels = labels.squeeze(1)  # Convert from (1, 1, 128, 128, 128) to (1, 128, 128, 128)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(inputs)\n",
    "        loss = loss_function(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        epoch_loss += loss.item()\n",
    "    print(f\"✅ Epoch {epoch+1} loss: {epoch_loss / len(train_loader):.4f}\")\n",
    "\n",
    "# ------------------ Save Model ------------------\n",
    "torch.save(model.state_dict(), \"3d_unet_brain_tumor_segmenter.pth\")\n",
    "print(\"✅ Saved trained segmentation model!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "cb442d8e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Evaluation Results:\n",
      "🎯 Avg Dice:     nan\n",
      "📦 Avg IoU:      0.5811\n",
      "✅ Avg Precision:0.5811\n",
      "🔁 Avg Recall:   0.5811\n",
      "📊 Avg F1 Score: 0.5811\n",
      "📈 Avg Accuracy: 0.9999\n"
     ]
    }
   ],
   "source": [
    "from monai.metrics import DiceMetric\n",
    "from sklearn.metrics import jaccard_score, precision_score, recall_score, f1_score\n",
    "import numpy as np\n",
    "import torch\n",
    "\n",
    "# Accuracy function\n",
    "def compute_accuracy(pred_mask, true_mask):\n",
    "    pred_flat = pred_mask.flatten()\n",
    "    true_flat = true_mask.flatten()\n",
    "    return np.mean(pred_flat == true_flat)\n",
    "\n",
    "# Set device\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model.eval()\n",
    "\n",
    "# Metrics containers\n",
    "dice_metric = DiceMetric(include_background=True, reduction=\"mean\")\n",
    "dice_vals, iou_vals, precision_vals, recall_vals, f1_vals, acc_vals = [], [], [], [], [], []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for batch in val_loader:\n",
    "        inputs = batch[\"image\"].to(device)\n",
    "        labels = batch[\"label\"].to(device)\n",
    "\n",
    "        outputs = model(inputs)                         # (B, 1, 128, 128, 128)\n",
    "        outputs = torch.sigmoid(outputs)                # Apply sigmoid for binary prediction\n",
    "        preds = (outputs > 0.5).float()                 # Threshold at 0.5\n",
    "\n",
    "        # Dice (on GPU)\n",
    "        dice_score = dice_metric(preds, labels)\n",
    "        dice_vals.append(dice_score.item())\n",
    "\n",
    "        # Move to CPU for scikit-learn metrics\n",
    "        preds_np = preds.cpu().numpy().squeeze()\n",
    "        labels_np = labels.cpu().numpy().squeeze()\n",
    "\n",
    "        pred_flat = preds_np.flatten()\n",
    "        label_flat = labels_np.flatten()\n",
    "\n",
    "        iou_vals.append(jaccard_score(label_flat, pred_flat, zero_division=0))\n",
    "        precision_vals.append(precision_score(label_flat, pred_flat, zero_division=0))\n",
    "        recall_vals.append(recall_score(label_flat, pred_flat, zero_division=0))\n",
    "        f1_vals.append(f1_score(label_flat, pred_flat, zero_division=0))\n",
    "        acc_vals.append(compute_accuracy(preds_np, labels_np))\n",
    "\n",
    "# Final output\n",
    "print(\"\\n🔍 Evaluation Results:\")\n",
    "print(f\"🎯 Avg Dice:     {np.mean(dice_vals):.4f}\")\n",
    "print(f\"📦 Avg IoU:      {np.mean(iou_vals):.4f}\")\n",
    "print(f\"✅ Avg Precision:{np.mean(precision_vals):.4f}\")\n",
    "print(f\"🔁 Avg Recall:   {np.mean(recall_vals):.4f}\")\n",
    "print(f\"📊 Avg F1 Score: {np.mean(f1_vals):.4f}\")\n",
    "print(f\"📈 Avg Accuracy: {np.mean(acc_vals):.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "70af3b67",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🎯 Avg Dice:     0.5811\n"
     ]
    }
   ],
   "source": [
    "# Initialize manually to track Dice\n",
    "dice_vals = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for batch in val_loader:\n",
    "        inputs = batch[\"image\"].to(device)\n",
    "        labels = batch[\"label\"].to(device)\n",
    "\n",
    "        outputs = model(inputs)\n",
    "        outputs = torch.sigmoid(outputs)\n",
    "        preds = (outputs > 0.5).float()\n",
    "\n",
    "        # Only compute Dice if either pred or label is not completely empty\n",
    "        if torch.sum(labels) > 0 or torch.sum(preds) > 0:\n",
    "            dice_score = (2. * (preds * labels).sum()) / (preds.sum() + labels.sum() + 1e-5)\n",
    "            dice_vals.append(dice_score.item())\n",
    "        else:\n",
    "            dice_vals.append(1.0)  # Both empty = perfect match (optional)\n",
    "\n",
    "        # Rest of your code...\n",
    "\n",
    "# Then at the end:\n",
    "print(f\"🎯 Avg Dice:     {np.mean(dice_vals):.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "31393d0e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Labels shape: torch.Size([1])\n"
     ]
    }
   ],
   "source": [
    "print(f\"Labels shape: {labels.shape}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
